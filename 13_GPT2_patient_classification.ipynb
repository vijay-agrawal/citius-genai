{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQrGOIewBu/TpZyBz+S/GU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Pain Level Classification Using GPT-2: Analysis of Patient Notes"],"metadata":{"id":"QFDBBxYDbDiA"}},{"cell_type":"markdown","source":["**Introduction**\n","\n","This project focuses on developing a machine learning model to classify patient pain levels based on their reported symptoms and notes. The dataset consists of clinical records containing patient notes, length of hospital stay, treatment information, and pain level assessments.\n","\n","**Dataset Overview**\n","\n","The dataset (patient_pain_data.csv) contains several key fields:\n","\n","- Patient Notes: Free-text descriptions of patient conditions and symptoms\n","- Days Admitted: Duration of hospital stay\n","- Treatment Type: Category of treatment (Surgery, Physiotherapy, Medication)\n","- Surgery Done: Whether surgery was performed (Yes/No)\n","- Pain Level: Numerical pain scale rating (target variable)\n","\n","Sample entries show a range of patient experiences, from \"I feel a little better today\" to \"The pain is unbearable,\" with corresponding pain levels ranging from 1-9 on a numerical scale. The pain level classification is treated as a multi-class problem with 9 distinct levels."],"metadata":{"id":"qYpxogmybE3L"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch.utils.data import Dataset\n","from transformers import (\n","    GPT2Tokenizer,\n","    GPT2ForSequenceClassification,\n","    Trainer,\n","    TrainingArguments\n",")\n"],"metadata":{"id":"Kic_B74ZTli3","executionInfo":{"status":"ok","timestamp":1739869572141,"user_tz":-330,"elapsed":26298,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"ZrcQXYWYJ5Zs","executionInfo":{"status":"ok","timestamp":1739869351420,"user_tz":-330,"elapsed":21003,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}},"outputId":"922be026-1e55-43a1-f7c0-f3986483ad7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive to access data\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Step 1: Load and inspect the dataset\n","# Load and display the dataset\n","df = pd.read_csv('/content/drive/My Drive/patient_pain_data.csv')\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"wuU0QmgDJ8K2","executionInfo":{"status":"ok","timestamp":1739869590129,"user_tz":-330,"elapsed":819,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}},"outputId":"6f2f8802-fb4d-4795-a764-3391a69e88dd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["                  Patient Notes  Days Admitted Treatment Type Surgery Done  \\\n","0  I feel a little better today              7        Surgery          Yes   \n","1        The pain is unbearable              4  Physiotherapy          Yes   \n","2       I can walk but it hurts             13     Medication          Yes   \n","3        I have a mild headache             11  Physiotherapy          Yes   \n","4     I can't sleep due to pain              8        Surgery          Yes   \n","\n","   Pain Level  \n","0           8  \n","1           7  \n","2           9  \n","3           8  \n","4           5  \n"]}]},{"cell_type":"code","source":["# Step 2: Extract texts and labels\n","texts = df['Patient Notes'].tolist()    # List of text notes\n","labels = df['Pain Level'].tolist()  # Corresponding labels"],"metadata":{"id":"AOrQ9KEHTy7Q","executionInfo":{"status":"ok","timestamp":1739869884559,"user_tz":-330,"elapsed":2425,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Step 3: Determine the number of unique classes\n","# Ensure labels start from 0 and are consecutive integers\n","unique_labels = sorted(list(set(labels)))  # Get unique labels and sort them\n","label_mapping = {label: i for i, label in enumerate(unique_labels)}  # Create a mapping\n","\n","# Map original labels to encoded labels\n","encoded_labels = [label_mapping[label] for label in labels]\n","num_labels = len(unique_labels)  # Update num_labels\n","\n","print(f\"Number of classes: {num_labels}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"hRoo2waRT43C","executionInfo":{"status":"ok","timestamp":1739870904692,"user_tz":-330,"elapsed":839,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}},"outputId":"87caf769-d2f2-4561-ec5b-164194ff306c"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes: 9\n"]}]},{"cell_type":"code","source":["\n","# Step 4: Split the data into training and validation sets (80/20 split)\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    texts, encoded_labels, test_size=0.2, random_state=42\n",")\n"],"metadata":{"id":"j2C1YwktT6TA","executionInfo":{"status":"ok","timestamp":1739871063935,"user_tz":-330,"elapsed":644,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# Step 5: Create a custom PyTorch Dataset class\n","class PatientNotesDataset(Dataset):\n","    \"\"\"\n","    Custom Dataset for patient/doctor notes.\n","    It tokenizes texts and returns input IDs, attention masks, and labels.\n","    \"\"\"\n","    def __init__(self, texts, labels, tokenizer, max_length=128):\n","        self.texts = texts\n","        self.labels = labels  # Now expects encoded labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts[idx])\n","        label = self.labels[idx]  # Accessing encoded label directly\n","        encoding = self.tokenizer(\n","            text,\n","            padding='max_length',  # Pad to max_length\n","            truncation=True,       # Truncate texts longer than max_length\n","            max_length=self.max_length,\n","            return_tensors='pt'\n","        )\n","        # Remove extra batch dimension and include the label\n","        item = {key: val.squeeze() for key, val in encoding.items()}\n","        item['labels'] = torch.tensor(label, dtype=torch.long)  # Using encoded label\n","        return item"],"metadata":{"id":"PH2mgsDsT8Iw","executionInfo":{"status":"ok","timestamp":1739871065151,"user_tz":-330,"elapsed":1218,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# Step 6: Initialize the GPT-2 tokenizer and model\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","# GPT-2 does not have a pad token by default; use the EOS token as the pad token.\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model = GPT2ForSequenceClassification.from_pretrained(\n","    \"gpt2\",\n","    num_labels=num_labels  # Configure for the correct number of classes\n",")\n","# Ensure the model's configuration knows about the padding token\n","model.config.pad_token_id = model.config.eos_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"-uLehb6eT9uf","executionInfo":{"status":"ok","timestamp":1739871065151,"user_tz":-330,"elapsed":5,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}},"outputId":"d003f94f-1442-4f32-e2db-bdab073cf6d0"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# Step 7: Create Dataset instances for training and validation\n","# Use encoded labels when creating the datasets\n","train_dataset = PatientNotesDataset(train_texts, train_labels, tokenizer, max_length=128)\n","val_dataset = PatientNotesDataset(val_texts, val_labels, tokenizer, max_length=128)\n"],"metadata":{"id":"SRa3K1YnT_H0","executionInfo":{"status":"ok","timestamp":1739871065151,"user_tz":-330,"elapsed":4,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["# Step 8: Define training arguments (wandb and other integrations disabled)\n","training_args = TrainingArguments(\n","    output_dir='./results',             # Directory for checkpoints and predictions\n","    num_train_epochs=3,                 # Number of training epochs\n","    per_device_train_batch_size=8,      # Batch size per device during training\n","    per_device_eval_batch_size=8,       # Batch size for evaluation\n","    evaluation_strategy=\"epoch\",        # Evaluate at the end of each epoch\n","    save_strategy=\"epoch\",              # Save a checkpoint at the end of each epoch\n","    logging_steps=10,                   # Log every 10 steps\n","    load_best_model_at_end=True,        # Load the best model based on evaluation loss\n","    metric_for_best_model=\"eval_loss\",  # Criterion for best model selection\n","    report_to=[],                       # Disable integrations like wandb\n",")\n"],"metadata":{"id":"3fK04K5uUA7-","executionInfo":{"status":"ok","timestamp":1739871065151,"user_tz":-330,"elapsed":4,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["# Step 9: Initialize the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"6nEPJ_OZUCsO","executionInfo":{"status":"ok","timestamp":1739871065151,"user_tz":-330,"elapsed":4,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}},"outputId":"38d73e54-a3cc-46b8-a1c4-1f33b01c8359"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-63-c911949f3bb2>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]}]},{"cell_type":"code","source":["# Step 10: Train the model\n","print(\"Starting training...\")\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"m_JW5F_xUELS","executionInfo":{"status":"ok","timestamp":1739871341203,"user_tz":-330,"elapsed":275385,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}},"outputId":"3f300a80-2eb2-4815-9e0d-b1d6aa41562a"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15/15 04:24, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.918393</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.792800</td>\n","      <td>2.304745</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.792800</td>\n","      <td>2.266632</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=15, training_loss=3.2614095052083334, metrics={'train_runtime': 275.8821, 'train_samples_per_second': 0.435, 'train_steps_per_second': 0.054, 'total_flos': 7839397969920.0, 'train_loss': 3.2614095052083334, 'epoch': 3.0})"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["# Step 11: Evaluate the model on the validation set\n","eval_results = trainer.evaluate()\n","print(\"Evaluation results:\")\n","print(eval_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"ZQDvIjQ3UFrq","executionInfo":{"status":"ok","timestamp":1739871345820,"user_tz":-330,"elapsed":4618,"user":{"displayName":"Riya Bangera","userId":"14768168566445102135"}},"outputId":"f62a1402-1f97-4ea3-c821-4a1aa897f2b3"},"execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2/2 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation results:\n","{'eval_loss': 2.266631841659546, 'eval_runtime': 3.8019, 'eval_samples_per_second': 2.63, 'eval_steps_per_second': 0.526, 'epoch': 3.0}\n"]}]}]}